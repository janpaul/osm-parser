import { open, stat } from "fs/promises"
import { inflateSync } from "zlib"
import { BlobHeader, Blob } from "./proto/fileformat_pb.js"
import { HeaderBlock, PrimitiveBlock } from "./proto/osmformat_pb.js"
import { toNetworkByteOrder, debug, info } from "./lib"

const [, , , inputFile] = process.argv
info(`parsing ${inputFile}`)

const textDecoder = new TextDecoder()

const getFilesizeInBytes = async (filename: string): Promise<number> => {
  const { size } = await stat(filename)
  return size
}
const getBlobData = (blob: Blob): Buffer => {
  let blobData
  if (blob.getRaw()) {
    debug("Blob contains data")
    blobData = blob.getRaw()
  } else {
    const zdata = blob.getZlibData()
    debug(`Blob contains zlib data of ${zdata.length}`)
    blobData = inflateSync(zdata)
  }
  // test if the data matches the expected but don't do anything with it
  if (blobData.length === blob.getRawSize()) {
    // debug("blob data matches expected length")
  } else {
    info("Blob data does NOT match expected length")
  }
  return blobData
}

export const parseStringTable = (block: PrimitiveBlock): string[] =>
  block
    .getStringtable()
    .getSList()
    .map((data) => {
      if (data instanceof String) {
        return data
      } else {
        return textDecoder.decode(data as Uint8Array)
      }
    }) as string[]

const main = async () => {
  const fileSize = await getFilesizeInBytes(inputFile)
  const f = await open(inputFile, "r")
  let bytesRead = 0

  while (bytesRead < fileSize) {
    // the first 4 bytes contain the length of the BlobHeader
    const blength = new Uint8Array(4)
    await f.read(blength, 0, 4)
    bytesRead += 4
    const blobHeaderSize = toNetworkByteOrder(blength)

    // using the length of the blob header, grab the blob header
    const bblobHeader = new Uint8Array(blobHeaderSize)
    bytesRead += blobHeaderSize
    await f.read(bblobHeader, 0, blobHeaderSize)
    const blobHeader = BlobHeader.deserializeBinary(bblobHeader)
    const dataSize = blobHeader.getDatasize()

    // the Blob is `dataSize` bytes in length. Go and grab it.
    const bblob = new Uint8Array(dataSize)
    bytesRead += dataSize
    await f.read(bblob, 0, dataSize)
    const blob = Blob.deserializeBinary(bblob)
    const blobData = getBlobData(blob)

    // depending on the type of the blobHeader, parse the data.
    if (blobHeader.getType() === "OSMHeader") {
      debug("parsing HeaderBlock")
      const headerBlock = HeaderBlock.deserializeBinary(blobData)
      info(`this osm.pbf was generated by ${headerBlock.getWritingprogram()}`)

      // debug(`listing required features:`)
      // const rfeatures = headerBlock.getRequiredFeaturesList()
      // for (const feature of rfeatures) {
      //   debug(`  ${feature}`)
      // }
      //
      // debug(`listing optional features:`)
      // const ofeatures = headerBlock.getOptionalFeaturesList()
      // for (const feature of ofeatures) {
      //   debug(`  ${feature}`)
      // }
    }
    if (blobHeader.getType() === "OSMData") {
      debug("parsing PrimitiveBlock")
      const primitiveBlock = PrimitiveBlock.deserializeBinary(blobData)
      const stringTable = parseStringTable(primitiveBlock)
      const granularity = primitiveBlock.getGranularity()
      const latOffset = primitiveBlock.getLatOffset()
      const lonOffset = primitiveBlock.getLonOffset()
      const dateGranularity = primitiveBlock.getDateGranularity()
      const calculateLatitude = (v: number): number => 0.000000001 * (latOffset + granularity * v)
      const calculateLongitude = (v: number): number => 0.000000001 * (lonOffset + granularity * v)
      const calculateDate = (v: number): number => v * dateGranularity

      for (const pgroup of primitiveBlock.getPrimitivegroupList()) {
        const dense = pgroup.getDense()
        if (dense) {
          info(`parsing dense nodes`)
        }
      }
    }
  }
}

main().then(() => info("Done"))
